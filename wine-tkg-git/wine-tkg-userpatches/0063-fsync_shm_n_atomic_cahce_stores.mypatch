From 0197b3cf70379b32512e2a830c818c165acb9224 Mon Sep 17 00:00:00 2001
From: Paul Gofman <pgofman@codeweavers.com>
Date: Mon, 1 Aug 2022 10:53:28 -0500
Subject: [PATCH] fsync: Increase shm page size.

CW-Bug-Id: #21050
---
 dlls/ntdll/unix/fsync.c | 19 +++++++++----------
 server/fsync.c          | 19 +++++++++----------
 server/protocol.def     |  2 ++
 3 files changed, 20 insertions(+), 20 deletions(-)

diff --git a/dlls/ntdll/unix/fsync.c b/dlls/ntdll/unix/fsync.c
index 951488129e9..85c39e390f2 100644
--- a/dlls/ntdll/unix/fsync.c
+++ b/dlls/ntdll/unix/fsync.c
@@ -227,14 +227,13 @@ static char shm_name[29];
 static int shm_fd;
 static void **shm_addrs;
 static int shm_addrs_size;  /* length of the allocated shm_addrs array */
-static long pagesize;
 
 static pthread_mutex_t shm_addrs_mutex = PTHREAD_MUTEX_INITIALIZER;
 
 static void *get_shm( unsigned int idx )
 {
-    int entry  = (idx * 16) / pagesize;
-    int offset = (idx * 16) % pagesize;
+    int entry  = (idx * 16) / FSYNC_SHM_PAGE_SIZE;
+    int offset = (idx * 16) % FSYNC_SHM_PAGE_SIZE;
     void *ret;
 
     pthread_mutex_lock( &shm_addrs_mutex );
@@ -251,14 +250,16 @@ static void *get_shm( unsigned int idx )
 
     if (!shm_addrs[entry])
     {
-        void *addr = mmap( NULL, pagesize, PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd, entry * pagesize );
+        void *addr = mmap( NULL, FSYNC_SHM_PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd,
+                           (off_t)entry * FSYNC_SHM_PAGE_SIZE );
         if (addr == (void *)-1)
-            ERR("Failed to map page %d (offset %#lx).\n", entry, entry * pagesize);
+            ERR("Failed to map page %d (offset %s).\n", entry,
+                 wine_dbgstr_longlong((off_t)entry * FSYNC_SHM_PAGE_SIZE));
 
         TRACE("Mapping page %d at %p.\n", entry, addr);
 
         if (__sync_val_compare_and_swap( &shm_addrs[entry], 0, addr ))
-            munmap( addr, pagesize ); /* someone beat us to it */
+            munmap( addr, FSYNC_SHM_PAGE_SIZE ); /* someone beat us to it */
     }
 
     ret = (void *)((unsigned long)shm_addrs[entry] + offset);
@@ -348,10 +349,10 @@ static unsigned int shm_index_from_shm( char *shm )
 
     for (i = 0; i < count; ++i)
     {
-        if (shm >= (char *)shm_addrs[i] && shm < (char *)shm_addrs[i] + pagesize)
+        if (shm >= (char *)shm_addrs[i] && shm < (char *)shm_addrs[i] + FSYNC_SHM_PAGE_SIZE)
         {
             idx_offset = (shm - (char *)shm_addrs[i]) / 16;
-            return i * (pagesize / 16) + idx_offset;
+            return i * (FSYNC_SHM_PAGE_SIZE / 16) + idx_offset;
         }
     }
 
@@ -597,8 +598,6 @@ void fsync_init(void)
         exit(1);
     }
 
-    pagesize = sysconf( _SC_PAGESIZE );
-
     shm_addrs = calloc( 128, sizeof(shm_addrs[0]) );
     shm_addrs_size = 128;
 }
diff --git a/server/fsync.c b/server/fsync.c
index ada3c217629..de74d5859b1 100644
--- a/server/fsync.c
+++ b/server/fsync.c
@@ -82,7 +82,6 @@ static int shm_fd;
 static off_t shm_size;
 static void **shm_addrs;
 static int shm_addrs_size;  /* length of the allocated shm_addrs array */
-static long pagesize;
 
 static int is_fsync_initialized;
 
@@ -118,12 +117,10 @@ void fsync_init(void)
     if (shm_fd == -1)
         perror( "shm_open" );
 
-    pagesize = sysconf( _SC_PAGESIZE );
-
     shm_addrs = calloc( 128, sizeof(shm_addrs[0]) );
     shm_addrs_size = 128;
 
-    shm_size = pagesize;
+    shm_size = FSYNC_SHM_PAGE_SIZE;
     if (ftruncate( shm_fd, shm_size ) == -1)
         perror( "ftruncate" );
 
@@ -214,8 +211,8 @@ static void fsync_destroy( struct object *obj )
 
 static void *get_shm( unsigned int idx )
 {
-    int entry  = (idx * 16) / pagesize;
-    int offset = (idx * 16) % pagesize;
+    int entry  = (idx * 16) / FSYNC_SHM_PAGE_SIZE;
+    int offset = (idx * 16) % FSYNC_SHM_PAGE_SIZE;
 
     if (entry >= shm_addrs_size)
     {
@@ -231,10 +228,12 @@ static void *get_shm( unsigned int idx )
 
     if (!shm_addrs[entry])
     {
-        void *addr = mmap( NULL, pagesize, PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd, entry * pagesize );
+        void *addr = mmap( NULL, FSYNC_SHM_PAGE_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd,
+                          (off_t)entry * FSYNC_SHM_PAGE_SIZE );
         if (addr == (void *)-1)
         {
-            fprintf( stderr, "fsync: failed to map page %d (offset %#lx): ", entry, entry * pagesize );
+            fprintf( stderr, "fsync: failed to map page %d (offset %#lx): ",
+                     entry, (off_t)entry * FSYNC_SHM_PAGE_SIZE );
             perror( "mmap" );
         }
 
@@ -242,7 +241,7 @@ static void *get_shm( unsigned int idx )
             fprintf( stderr, "fsync: Mapping page %d at %p.\n", entry, addr );
 
         if (__sync_val_compare_and_swap( &shm_addrs[entry], 0, addr ))
-            munmap( addr, pagesize ); /* someone beat us to it */
+            munmap( addr, FSYNC_SHM_PAGE_SIZE ); /* someone beat us to it */
     }
 
     return (void *)((unsigned long)shm_addrs[entry] + offset);
@@ -299,7 +298,7 @@ unsigned int fsync_alloc_shm( int low, int high )
     while (shm_idx * 16 >= shm_size)
     {
         /* Better expand the shm section. */
-        shm_size += pagesize;
+        shm_size += FSYNC_SHM_PAGE_SIZE;
         if (ftruncate( shm_fd, shm_size ) == -1)
         {
             fprintf( stderr, "fsync: couldn't expand %s to size %jd: ",
diff --git a/server/protocol.def b/server/protocol.def
index 23cd43c22ca..8903a23af32 100644
--- a/server/protocol.def
+++ b/server/protocol.def
@@ -3870,6 +3870,8 @@ enum esync_type
 @REQ(get_esync_apc_fd)
 @END
 
+#define FSYNC_SHM_PAGE_SIZE 0x10000
+
 enum fsync_type
 {
     FSYNC_SEMAPHORE = 1,

From 024db18f7c2b61659c98347f19fbb602f0b9aa8b Mon Sep 17 00:00:00 2001
From: Paul Gofman <pgofman@codeweavers.com>
Date: Mon, 1 Aug 2022 11:01:51 -0500
Subject: [PATCH] fsync: Use static shm_addrs array and get rid of locking in
 get_shm().

CW-Bug-Id: #21050
---
 dlls/ntdll/unix/fsync.c | 31 +++++++------------------------
 1 file changed, 7 insertions(+), 24 deletions(-)

diff --git a/dlls/ntdll/unix/fsync.c b/dlls/ntdll/unix/fsync.c
index 85c39e390f2..a90eca5ce76 100644
--- a/dlls/ntdll/unix/fsync.c
+++ b/dlls/ntdll/unix/fsync.c
@@ -225,27 +225,18 @@ C_ASSERT(sizeof(struct mutex) == 16);
 
 static char shm_name[29];
 static int shm_fd;
-static void **shm_addrs;
-static int shm_addrs_size;  /* length of the allocated shm_addrs array */
-
-static pthread_mutex_t shm_addrs_mutex = PTHREAD_MUTEX_INITIALIZER;
+static volatile void *shm_addrs[8192];
 
 static void *get_shm( unsigned int idx )
 {
     int entry  = (idx * 16) / FSYNC_SHM_PAGE_SIZE;
     int offset = (idx * 16) % FSYNC_SHM_PAGE_SIZE;
-    void *ret;
-
-    pthread_mutex_lock( &shm_addrs_mutex );
 
-    if (entry >= shm_addrs_size)
+    if (entry >= ARRAY_SIZE(shm_addrs))
     {
-        int new_size = max(shm_addrs_size * 2, entry + 1);
-
-        if (!(shm_addrs = realloc( shm_addrs, new_size * sizeof(shm_addrs[0]) )))
-            ERR("Failed to grow shm_addrs array to size %d.\n", shm_addrs_size);
-        memset( shm_addrs + shm_addrs_size, 0, (new_size - shm_addrs_size) * sizeof(shm_addrs[0]) );
-        shm_addrs_size = new_size;
+        ERR( "idx %u exceeds maximum of %u.\n", idx,
+             (unsigned int)ARRAY_SIZE(shm_addrs) * (FSYNC_SHM_PAGE_SIZE / 16) );
+        return NULL;
     }
 
     if (!shm_addrs[entry])
@@ -262,11 +253,7 @@ static void *get_shm( unsigned int idx )
             munmap( addr, FSYNC_SHM_PAGE_SIZE ); /* someone beat us to it */
     }
 
-    ret = (void *)((unsigned long)shm_addrs[entry] + offset);
-
-    pthread_mutex_unlock( &shm_addrs_mutex );
-
-    return ret;
+    return (char *)shm_addrs[entry] + offset;
 }
 
 /* We'd like lookup to be fast. To that end, we use a static list indexed by handle.
@@ -344,10 +331,9 @@ static void grab_object( struct fsync *obj )
 
 static unsigned int shm_index_from_shm( char *shm )
 {
-    unsigned int count = shm_addrs_size;
     unsigned int i, idx_offset;
 
-    for (i = 0; i < count; ++i)
+    for (i = 0; i < ARRAY_SIZE(shm_addrs); ++i)
     {
         if (shm >= (char *)shm_addrs[i] && shm < (char *)shm_addrs[i] + FSYNC_SHM_PAGE_SIZE)
         {
@@ -597,9 +583,6 @@ void fsync_init(void)
             ERR("Failed to initialize shared memory: %s\n", strerror( errno ));
         exit(1);
     }
-
-    shm_addrs = calloc( 128, sizeof(shm_addrs[0]) );
-    shm_addrs_size = 128;
 }
 
 NTSTATUS fsync_create_semaphore( HANDLE *handle, ACCESS_MASK access,

From 82c40ec171fa87831d78148c11e400ec094afa19 Mon Sep 17 00:00:00 2001
From: Paul Gofman <pgofman@codeweavers.com>
Date: Mon, 1 Aug 2022 10:50:13 -0500
Subject: [PATCH] fsync: Use atomic cache stores and load instead of locking
 cache.

CW-Bug-Id: #21050

(replaces "fsync: Synchronize access to object cache.")
---
 dlls/ntdll/unix/fsync.c | 96 ++++++++++++++++++-----------------------
 1 file changed, 43 insertions(+), 53 deletions(-)

diff --git a/dlls/ntdll/unix/fsync.c b/dlls/ntdll/unix/fsync.c
index a90eca5ce76..5d8023de884 100644
--- a/dlls/ntdll/unix/fsync.c
+++ b/dlls/ntdll/unix/fsync.c
@@ -262,9 +262,16 @@ static void *get_shm( unsigned int idx )
 #define FSYNC_LIST_BLOCK_SIZE  (65536 / sizeof(struct fsync))
 #define FSYNC_LIST_ENTRIES     256
 
-static struct fsync *fsync_list[FSYNC_LIST_ENTRIES];
-static struct fsync fsync_list_initial_block[FSYNC_LIST_BLOCK_SIZE];
-static int cache_locked;
+struct fsync_cache
+{
+    enum fsync_type type;
+    unsigned int shm_idx;
+};
+
+C_ASSERT(sizeof(struct fsync_cache) == sizeof(uint64_t));
+
+static struct fsync_cache *fsync_list[FSYNC_LIST_ENTRIES];
+static struct fsync_cache fsync_list_initial_block[FSYNC_LIST_BLOCK_SIZE];
 
 static inline UINT_PTR handle_to_index( HANDLE handle, UINT_PTR *entry )
 {
@@ -273,29 +280,10 @@ static inline UINT_PTR handle_to_index( HANDLE handle, UINT_PTR *entry )
     return idx % FSYNC_LIST_BLOCK_SIZE;
 }
 
-static void small_pause(void)
-{
-#ifdef __i386__
-    __asm__ __volatile__( "rep;nop" : : : "memory" );
-#else
-    __asm__ __volatile__( "" : : : "memory" );
-#endif
-}
-
-static void lock_obj_cache(void)
-{
-    while (__sync_val_compare_and_swap( &cache_locked, 0, 1 ))
-        small_pause();
-}
-
-static void unlock_obj_cache(void)
-{
-    __atomic_store_n( &cache_locked, 0, __ATOMIC_SEQ_CST );
-}
-
-static void add_to_list( HANDLE handle, enum fsync_type type, void *shm )
+static void add_to_list( HANDLE handle, enum fsync_type type, unsigned int shm_idx )
 {
     UINT_PTR entry, idx = handle_to_index( handle, &entry );
+    struct fsync_cache cache;
 
     if (entry >= FSYNC_LIST_ENTRIES)
     {
@@ -308,18 +296,17 @@ static void add_to_list( HANDLE handle, enum fsync_type type, void *shm )
         if (!entry) fsync_list[0] = fsync_list_initial_block;
         else
         {
-            void *ptr = anon_mmap_alloc( FSYNC_LIST_BLOCK_SIZE * sizeof(struct fsync),
+            void *ptr = anon_mmap_alloc( FSYNC_LIST_BLOCK_SIZE * sizeof(*fsync_list[entry]),
                                          PROT_READ | PROT_WRITE );
             if (ptr == MAP_FAILED) return;
             if (__sync_val_compare_and_swap( &fsync_list[entry], NULL, ptr ))
-                munmap( ptr, FSYNC_LIST_BLOCK_SIZE * sizeof(struct fsync) );
+                munmap( ptr, FSYNC_LIST_BLOCK_SIZE * sizeof(*fsync_list[entry]) );
         }
     }
 
-    lock_obj_cache();
-    fsync_list[entry][idx].type = type;
-    fsync_list[entry][idx].shm = shm;
-    unlock_obj_cache();
+    cache.type = type;
+    cache.shm_idx = shm_idx;
+    __atomic_store_n( (uint64_t *)&fsync_list[entry][idx], *(uint64_t *)&cache, __ATOMIC_SEQ_CST );
 }
 
 static void grab_object( struct fsync *obj )
@@ -376,22 +363,29 @@ static void put_object_from_wait( struct fsync *obj )
 
 static BOOL get_cached_object( HANDLE handle, struct fsync *obj )
 {
-    BOOL ret = TRUE;
     UINT_PTR entry, idx = handle_to_index( handle, &entry );
+    struct fsync_cache cache;
 
     if (entry >= FSYNC_LIST_ENTRIES || !fsync_list[entry]) return FALSE;
 
-    lock_obj_cache();
-    if (!fsync_list[entry][idx].type) ret = FALSE;
-    else
+again:
+    *(uint64_t *)&cache = __atomic_load_n( (uint64_t *)&fsync_list[entry][idx], __ATOMIC_SEQ_CST );
+
+    if (!cache.type || !cache.shm_idx) return FALSE;
+
+    obj->type = cache.type;
+    obj->shm = get_shm( cache.shm_idx );
+    grab_object( obj );
+    if (((int *)obj->shm)[2] < 2 ||
+        *(uint64_t *)&cache != __atomic_load_n( (uint64_t *)&fsync_list[entry][idx], __ATOMIC_SEQ_CST ))
     {
-        *obj = fsync_list[entry][idx];
-        grab_object( obj );
-        /* Here inside cache lock we should have at least one reference previously held by our handle. */
-        assert( ((int *)obj->shm)[2] > 1 );
+        /* This check does not strictly guarantee that we avoid the potential race but is supposed to greatly
+         * reduce the probability of that. */
+        put_object( obj );
+        FIXME( "Cache changed while getting object.\n" );
+        goto again;
     }
-    unlock_obj_cache();
-    return ret;
+    return TRUE;
 }
 
 /* Gets an object. This is either a proper fsync object (i.e. an event,
@@ -434,7 +428,7 @@ static NTSTATUS get_object( HANDLE handle, struct fsync *obj )
 
     obj->type = type;
     obj->shm = get_shm( shm_idx );
-    add_to_list( handle, type, obj->shm );
+    add_to_list( handle, type, shm_idx );
     /* get_fsync_idx server request increments shared mem refcount, so not grabbing object here. */
     return ret;
 }
@@ -461,17 +455,13 @@ NTSTATUS fsync_close( HANDLE handle )
 
     if (entry < FSYNC_LIST_ENTRIES && fsync_list[entry])
     {
-        enum fsync_type type;
+        struct fsync_cache cache;
 
-        lock_obj_cache();
-        if ((type = fsync_list[entry][idx].type))
-        {
-            fsync_list[entry][idx].type = 0;
-            fsync_list[entry][idx].shm = NULL;
-        }
-        unlock_obj_cache();
-        if (type)
-            return STATUS_SUCCESS;
+        cache.type = 0;
+        cache.shm_idx = 0;
+        *(uint64_t *)&cache = __atomic_exchange_n( (uint64_t *)&fsync_list[entry][idx],
+                                                   *(uint64_t *)&cache, __ATOMIC_SEQ_CST );
+        if (cache.type) return STATUS_SUCCESS;
     }
 
     return STATUS_INVALID_HANDLE;
@@ -506,7 +496,7 @@ static NTSTATUS create_fsync( enum fsync_type type, HANDLE *handle,
 
     if (!ret || ret == STATUS_OBJECT_NAME_EXISTS)
     {
-        add_to_list( *handle, type, get_shm( shm_idx ));
+        add_to_list( *handle, type, shm_idx );
         TRACE("-> handle %p, shm index %d.\n", *handle, shm_idx);
     }
 
@@ -539,7 +529,7 @@ static NTSTATUS open_fsync( enum fsync_type type, HANDLE *handle,
 
     if (!ret)
     {
-        add_to_list( *handle, type, get_shm( shm_idx ) );
+        add_to_list( *handle, type, shm_idx );
 
         TRACE("-> handle %p, shm index %u.\n", *handle, shm_idx);
     }

